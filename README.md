# CSCI1470_Final_Project

In the early days of gaming, graphics were simple — often limited to just 8-bit pixel art, as seen in classics like Super Mario. Today, thanks to advancements in AI-generated graphics and cutting-edge rendering technologies, video games have achieved breathtaking levels of realism and detail, delivering immersive visual experiences that were once unimaginable. This dramatic leap in visual fidelity led us, a group of avid gamers, to ask an important question: What other senses could be enhanced to make games even more immersive?

We noticed that while modern games are more immersive and visually diverse than ever, much of this immersion is focused on sight and sound, leaving other sensory cues—such as scent—largely underexplored. One natural next step is the sense of smell — an often overlooked but powerful component of human experience. Our project aims to address this gap by building a model that learns to associate “scent profiles” with specific game scenes. In other words, we want the model to look at a screenshot from a game and infer which scents might be present (e.g., “muddy,” “fresh,” “chemical,” “bloody”), and at what relative intensities.

We explore how to bring scents into gaming by leveraging deep learning (DL) and computer vision (CV) models. This model forms the core of a broader vision: to enable real-time scent generation in games through an intelligent scent-emitting device. By accurately predicting scent profiles from visuals, the model provides the essential bridge between the digital environment and the physical sensory experience, ultimately aiming to enhance gameplay immersion through smell. We view this primarily as a multi-label classification task, because the output is a normalized set of intensities across multiple scent categories. By predicting these scent distributions, we hope to lay a foundation for enhancing player immersion through more nuanced in-game feedback—potentially influencing how games could respond dynamically to a player’s sensory preferences.
